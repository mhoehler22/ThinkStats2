{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60bb64f8",
   "metadata": {},
   "source": [
    "* DSC530: Week 8\n",
    "* 8.2 Exercise\n",
    "* Marty Hoehler\n",
    "* 5-5-24\n",
    "\n",
    "# Exercise 9-1\n",
    "\n",
    "First, we'll download data and import libraries as in weeks prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f39999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from os.path import basename, exists\n",
    "\n",
    "def download(url):\n",
    "    filename = basename(url)\n",
    "    if not exists(filename):\n",
    "        from urllib.request import urlretrieve\n",
    "\n",
    "        local, _ = urlretrieve(url, filename)\n",
    "        print(\"Downloaded \" + local)\n",
    "\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/thinkstats2.py\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/thinkplot.py\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/nsfg.py\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/scatter.py\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/2002FemPreg.dct\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/2002FemPreg.dat.gz\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/first.py\")\n",
    "\n",
    "import nsfg\n",
    "import thinkstats2\n",
    "import thinkplot\n",
    "import first\n",
    "\n",
    "live, firsts, others = first.MakeFrames()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af02c805",
   "metadata": {},
   "source": [
    "In the text, they did two \"difference in Means\" tests, (one for the length of pregnancy, and one for the birth weight.)  They also did a correlation test between mother age and total weight and a Chi-Squared test of pregnancy length.  First, we'll bring in the classes from the text.  \n",
    "\n",
    "Each of these classes has a \"TestStatistic\" funcion that defines the statistic we will be finding a p-value on.\n",
    " - For the difference in means, we are taking the absolute value of the difference of the two means.\n",
    " - For the correlation calculation, the test statistic is the absolute value of the correlation coefficient.\n",
    " - For the Chi squared test, the statistic is the sum of the squared differences of observed minus expected, divided by expected.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f38a7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffMeansPermute(thinkstats2.HypothesisTest):\n",
    "\n",
    "    def TestStatistic(self, data):\n",
    "        group1, group2 = data\n",
    "        test_stat = abs(group1.mean() - group2.mean())\n",
    "        return test_stat\n",
    "\n",
    "    def MakeModel(self):\n",
    "        group1, group2 = self.data\n",
    "        self.n, self.m = len(group1), len(group2)\n",
    "        self.pool = np.hstack((group1, group2))\n",
    "\n",
    "    def RunModel(self):\n",
    "        np.random.shuffle(self.pool)\n",
    "        data = self.pool[:self.n], self.pool[self.n:]\n",
    "        return data\n",
    "    \n",
    "class CorrelationPermute(thinkstats2.HypothesisTest):\n",
    "\n",
    "    def TestStatistic(self, data):\n",
    "        xs, ys = data\n",
    "        test_stat = abs(thinkstats2.Corr(xs, ys))\n",
    "        return test_stat\n",
    "\n",
    "    def RunModel(self):\n",
    "        xs, ys = self.data\n",
    "        xs = np.random.permutation(xs)\n",
    "        return xs, ys\n",
    "\n",
    "class PregLengthTest(thinkstats2.HypothesisTest):\n",
    "\n",
    "    def MakeModel(self):\n",
    "        firsts, others = self.data\n",
    "        self.n = len(firsts)\n",
    "        self.pool = np.hstack((firsts, others))\n",
    "\n",
    "        pmf = thinkstats2.Pmf(self.pool)\n",
    "        self.values = range(35, 44)\n",
    "        self.expected_probs = np.array(pmf.Probs(self.values))\n",
    "\n",
    "    def RunModel(self):\n",
    "        np.random.shuffle(self.pool)\n",
    "        data = self.pool[:self.n], self.pool[self.n:]\n",
    "        return data\n",
    "    \n",
    "    def TestStatistic(self, data):\n",
    "        firsts, others = data\n",
    "        stat = self.ChiSquared(firsts) + self.ChiSquared(others)\n",
    "        return stat\n",
    "\n",
    "    def ChiSquared(self, lengths):\n",
    "        hist = thinkstats2.Hist(lengths)\n",
    "        observed = np.array(hist.Freqs(self.values))\n",
    "        expected = self.expected_probs * len(lengths)\n",
    "        stat = sum((observed - expected)**2 / expected)\n",
    "        return stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb7a04c",
   "metadata": {},
   "source": [
    "Next, using the text as a guide, we'll create a function that runs the four tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f0f8091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_test(live2):\n",
    "\n",
    "    # Labeling the main data sets as 'live2', 'firsts2', 'others2' to help me \n",
    "    # keep it straight from the versions defined above.\n",
    "    n = len(live2)\n",
    "    firsts2 = live2[live2.birthord == 1]\n",
    "    others2 = live2[live2.birthord != 1]\n",
    "    \n",
    "    # Difference of means for the length of the pregnancy (first child vs other children)\n",
    "    \n",
    "    data = firsts2.prglngth.values, others2.prglngth.values\n",
    "    ht = DiffMeansPermute(data)\n",
    "    pvalue1 = ht.PValue()\n",
    "    \n",
    "    # Difference of means for the weight of the child (first child vs other children)\n",
    "    # Note - the solution code recommended dropping null values for this section, so I've added that.\n",
    "    data2 = firsts2.totalwgt_lb.dropna().values, others2.totalwgt_lb.dropna().values\n",
    "    ht2 = DiffMeansPermute(data2)\n",
    "    pvalue2 = ht2.PValue()\n",
    "    \n",
    "    # Correlation test for the age of the mother vs the weight of the child\n",
    "    cleaned = live2.dropna(subset=['agepreg', 'totalwgt_lb'])\n",
    "    data3 = cleaned.agepreg.values, cleaned.totalwgt_lb.values\n",
    "    ht3 = CorrelationPermute(data3)\n",
    "    pvalue3 = ht3.PValue()\n",
    "    \n",
    "    # Chi Squared test for the pregnancy length (first child vs other children)\n",
    "    data4 = firsts2.prglngth.values, others2.prglngth.values\n",
    "    ht4 = PregLengthTest(data4)\n",
    "    pvalue4 = ht4.PValue()\n",
    "    \n",
    "    # Using the recommended formatting from the solution text to give us two decimals.\n",
    "    print('%d\\t%0.2f\\t%0.2f\\t%0.2f\\t%0.2f' % (n, pvalue1, pvalue2, pvalue3, pvalue4))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b3c3df",
   "metadata": {},
   "source": [
    "#### Full Sample tests\n",
    "Next, we'll find the p-values with the full sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e098f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9148\t0.15\t0.00\t0.00\t0.00\n"
     ]
    }
   ],
   "source": [
    "p_test(live)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ab3936",
   "metadata": {},
   "source": [
    "The p-values found in this recreation of the text examples are similar to the results that came from the book.  \n",
    "\n",
    "#### Tests with smaller samples\n",
    "Next, we'll use the recommended \"thinkstats2.SampleRows\" function to create samples of the \"live\" set that are various sizes.  First, I'd like to see a sample of about 6000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4855b105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\t0.48\t0.00\t0.00\t0.00\n"
     ]
    }
   ],
   "source": [
    "live6000 = thinkstats2.SampleRows(live, 6000)\n",
    "p_test(live6000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ce9a91",
   "metadata": {},
   "source": [
    "The p-value for test 1 has already started to increase with 6000 in the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aadd9b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\t0.34\t0.03\t0.00\t0.00\n"
     ]
    }
   ],
   "source": [
    "live3000 = thinkstats2.SampleRows(live, 3000)\n",
    "p_test(live3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff175c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\t0.67\t0.00\t0.48\t0.25\n"
     ]
    }
   ],
   "source": [
    "live1000 = thinkstats2.SampleRows(live, 1000)\n",
    "p_test(live1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "befb585f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\t0.56\t0.26\t0.09\t0.04\n"
     ]
    }
   ],
   "source": [
    "live500 = thinkstats2.SampleRows(live, 500)\n",
    "p_test(live500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "341e7772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\t0.87\t0.09\t0.02\t0.48\n"
     ]
    }
   ],
   "source": [
    "live100 = thinkstats2.SampleRows(live, 100)\n",
    "p_test(live100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0796d237",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "The p-tests are fluctuating more and more as the sample size n decreases.  For the most part, the tests that were positive with a large sample size become negative as we decrease the sample size.  But some positive results still happen, showing us the danger of using a small sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d540f7c8",
   "metadata": {},
   "source": [
    "# Exercise 10-1\n",
    "\n",
    "First, we will import the BRFSS code and data and import the library.  Then, we'll build the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "203ee452",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/brfss.py\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/CDBRFS08.ASC.gz\")\n",
    "import brfss\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de9c8f6",
   "metadata": {},
   "source": [
    "Next, we'll build the data frame for the heights and the log of the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2e3e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = brfss.ReadBrfss(nrows=None)\n",
    "df = df.dropna(subset=['htm3', 'wtkg2'])\n",
    "heights, weights = df.htm3, df.wtkg2\n",
    "log_weights = np.log10(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f12155b",
   "metadata": {},
   "source": [
    "\"thinkstats2\" provides a least squares formula for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba64005e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.993080416391762, 0.005281454169418105)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter, slope = thinkstats2.LeastSquares(heights, log_weights)\n",
    "inter, slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a14207",
   "metadata": {},
   "source": [
    "These parameters would not make very much intuitive sense in presentation.\n",
    "\n",
    "### Explaining the Intercept\n",
    "- The intercept would be the estimated log of the weight of someone that is 0 cm tall.  The book suggests that you instead present the intercept at the mean of x.  It's much more helpful to say \"the expected weight of someone x cm tall is y\" as opposed to \"if there were a person 0 cm tall, we would expect the log of his weight to be .993080416391762.\"\n",
    "- Instead, we'll find the mean height of the population and use our linear parameters to estimate the expected weight for that height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06c14d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.80947249428195"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, we find the log(weight) expected at the mean height using the linear formula y=mx+b\n",
    "exp_log_wgt = slope*np.mean(heights)+ inter\n",
    "# Now, we undo the base 10 log to find the expected weight.\n",
    "exp_wgt = 10**exp_log_wgt\n",
    "exp_wgt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369989a4",
   "metadata": {},
   "source": [
    "From this, we can say that the a person of the mean height would be 76.8 kg.  This is much more intuitive than trying to explain the y intercept.\n",
    "\n",
    "### Explaining the Slope\n",
    "\n",
    "For a more intuitive explanation of the slope, I found this discussion:\n",
    "http://www-stat.wharton.upenn.edu/~stine/stat621/handouts/LogsInRegression.pdf\n",
    "\n",
    "The author points out:\n",
    "- When you describe a linear slope, you describe it in terms of units of change.  \n",
    "- When you describe a log-transformed linear scope, you can describe it in terms of percent change.\n",
    "\n",
    "For our purposes, the linear model is:\n",
    "    Log<sub>10</sub>(Weight) = slope * Height + inter\n",
    "    \n",
    "So we could use that calculation to determine what a 20% increase in weight would mean.\n",
    "Log<sub>10</sub>(1.2 * Weight) = Log<sub>10</sub>(Weight) + Log<sub>10</sub>(1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "addfbb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07918124604762482"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log10(1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e11a00",
   "metadata": {},
   "source": [
    "So we could say that an increase in height of 8cm would increase the expected weight by 20%.\n",
    "\n",
    "### Goodness of Fit\n",
    "There were two methods mentioned in the text for judging goodness of fit.  \n",
    "\n",
    "#### Comparing Residual error to Standard Deviation\n",
    "First, is finding the RMSE of the residuals (called \"Std(res)\" in the text) and comparing it to the standard deviation of the data (\"Std(ys)\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21a1ac86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std_y: 1.2682569482092687 kg\n",
      "std_residuals: 1.2229473795518997 kg\n"
     ]
    }
   ],
   "source": [
    "std_y = thinkstats2.Std(log_weights)\n",
    "res = thinkstats2.Residuals(heights, log_weights, inter, slope)\n",
    "std_res = thinkstats2.Std(res)\n",
    "\n",
    "# Since weight is log-transformed, we'll convert them back to kg.\n",
    "print('std_y:', 10**std_y, 'kg')\n",
    "print('std_residuals:', 10**std_res, 'kg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58c3fbd",
   "metadata": {},
   "source": [
    "Based on this, the linear model improves the prediction of weight by about 46 grams.  \n",
    "\n",
    "#### Coefficient of Determination:  R<sup>2</sup>\n",
    "Another method of finding goodness of fit is to find R.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ed0b2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2827349431189432"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_2 = thinkstats2.CoefDetermination(log_weights, res)\n",
    "R_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f23166",
   "metadata": {},
   "source": [
    "This can be interpreted as meaning that knowing the height of a person predicts about 28% of the variance in the log of the weight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc86348",
   "metadata": {},
   "source": [
    "### Using Resampling to correct for weighted samples\n",
    "\n",
    "We will use the thinkstats2 library's functions: \"ResampleRows\" and \"ResampleRowsWeighted.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8272960e",
   "metadata": {},
   "source": [
    "The author also provided the following summary function (pg 121), using the thinkstats2 library of summary statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b64a1e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Summarize(estimates, actual=None):\n",
    "    mean = thinkstats2.Mean(estimates)\n",
    "    stderr = thinkstats2.Std(estimates, mu=actual)\n",
    "    cdf = thinkstats2.Cdf(estimates)\n",
    "    ci = cdf.ConfidenceInterval(90)\n",
    "    print('mean, SE, CI', mean, stderr, ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcf77299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean, SE, CI 168.9570137078356 0.01356298568748001 (168.9338810404414, 168.9773312920633)\n"
     ]
    }
   ],
   "source": [
    "estimates_unweighted = [thinkstats2.ResampleRows(df).htm3.mean() for _ in range(100)]\n",
    "Summarize(estimates_unweighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb5db84",
   "metadata": {},
   "source": [
    "The \"ResampleRowsWeighted()\" function in thinkstats2 takes the weight field provided and uses it to assign a probability \"p\" which is used in the random choice calculation to create a sample that is re-weighted.  I used the \"head()\" function and confirmed that the weight column is called 'finalwt', and not 'totalwt' as it says in some copies of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4e67c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>wtyrago</th>\n",
       "      <th>finalwt</th>\n",
       "      <th>wtkg2</th>\n",
       "      <th>htm3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82.0</td>\n",
       "      <td>2</td>\n",
       "      <td>76.363636</td>\n",
       "      <td>185.870345</td>\n",
       "      <td>70.91</td>\n",
       "      <td>157.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.0</td>\n",
       "      <td>2</td>\n",
       "      <td>72.727273</td>\n",
       "      <td>126.603027</td>\n",
       "      <td>72.73</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>73.636364</td>\n",
       "      <td>517.926275</td>\n",
       "      <td>73.64</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>88.636364</td>\n",
       "      <td>1252.624630</td>\n",
       "      <td>88.64</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>118.181818</td>\n",
       "      <td>415.161314</td>\n",
       "      <td>109.09</td>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex     wtyrago      finalwt   wtkg2   htm3\n",
       "0  82.0    2   76.363636   185.870345   70.91  157.0\n",
       "1  65.0    2   72.727273   126.603027   72.73  163.0\n",
       "3  61.0    1   73.636364   517.926275   73.64  170.0\n",
       "4  26.0    1   88.636364  1252.624630   88.64  185.0\n",
       "5  42.0    1  118.181818   415.161314  109.09  183.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "937cb37b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean, SE, CI 170.49923780795893 0.01719119267199965 (170.47426686068837, 170.5276809353463)\n"
     ]
    }
   ],
   "source": [
    "estimates_weighted = [thinkstats2.ResampleRowsWeighted(df, 'finalwt').htm3.mean() for _ in range(100)]\n",
    "Summarize(estimates_weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b892cd5",
   "metadata": {},
   "source": [
    "We can see that by resampling with the weights taken into account, we get a mean height that is about 1.5 cm taller.  \n",
    "- The sampling error is only about .02 cm, so the difference in mean is much larger than what we would expect to see from re-sampling.  \n",
    "- The confidence interval does not appear to be much changed in size.  In both the unweighted and the weighted, the spread is about .05cm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
