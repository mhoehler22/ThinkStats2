{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f70dda92",
   "metadata": {},
   "source": [
    "* DSC530: Week 5\n",
    "* 5.2 Exercise\n",
    "* Marty Hoehler\n",
    "* 4-14-24\n",
    "\n",
    "# Exercise 5-1\n",
    "\n",
    "If members of the Blue Man Group must be between 5'10\" and 6'1\", that's between 70 and 73 inches.  (I could apply!  I'm 6' even.)\n",
    "To work with the normal distribution in the text, we'll need to convert that to cm, using 2.54 as the coversion factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9693088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177.8"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_ht= 70*2.54\n",
    "lower_ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42833819",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185.42000000000002"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_ht= 73*2.54\n",
    "upper_ht"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab3db76",
   "metadata": {},
   "source": [
    "Next, we import the scipy package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a79dca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd525f3",
   "metadata": {},
   "source": [
    "We need to find the probability of being inbetween 177.8 and 185.42cm.  First we determine the probability of being under 177.8cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aceac7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48963902786483265"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = 178\n",
    "std = 7.7\n",
    "\n",
    "cdf_low =scipy.stats.norm.cdf(lower_ht, loc=mean, scale=std)\n",
    "cdf_low"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b506624",
   "metadata": {},
   "source": [
    "Next, we need the probability of being under 185.42cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dbc37e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8323858654963072"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf_high =scipy.stats.norm.cdf(upper_ht, loc=mean, scale=std)\n",
    "cdf_high"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b828341",
   "metadata": {},
   "source": [
    "The probability of being between 185.42cm and 177.8cm is the difference of the upper and lower cdfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a834dd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34274683763147457"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_blue_man = cdf_high - cdf_low\n",
    "prob_blue_man"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbed6f59",
   "metadata": {},
   "source": [
    "So about 34% of the male population is the right height to be eligible for the Blue Man Group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d025a5de",
   "metadata": {},
   "source": [
    "# Exercise 5-2\n",
    "If we try to fit our height data to the Pareto distribution we will get some unusual results.  First, we will build the distribution and confirm that the median matches what they found in the text.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09c2f89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5034066538560549"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "param_x = 1\n",
    "param_a = 1.7\n",
    "\n",
    "pareto_dist = scipy.stats.pareto(b=param_a, scale=param_x)\n",
    "pareto_dist.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e97654a",
   "metadata": {},
   "source": [
    "The book said the median worked out to 1.5, so this matches.  Next the assignment asks for the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42830e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.428571428571429"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pareto_mean = pareto_dist.mean()\n",
    "pareto_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2b7288",
   "metadata": {},
   "source": [
    "We are already seeing why the Pareto is an inappropriate model for height.  2.43 meters is almost 8 feet tall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27479942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.778739697565288"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pareto_dist.cdf(pareto_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4358996",
   "metadata": {},
   "source": [
    "About 78% of the population would fall below the mean of about 8 feet tall.  That leaves about 22% of the population above 8 feet tall.  Next, to find the number of people greater than a km tall, we would find the probability of that, (1 minus the probability of being under a kilometer tall) and then multiplying it by 7 billion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ec2db82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55602.976430479954"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 - pareto_dist.cdf(1000))*7000000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d199041",
   "metadata": {},
   "source": [
    "We would have over 55K people over a km tall.  To find the tallest person, we find the probability of being the 7 billionth person, and then using the percent point function (which is the inverse of the cdf) to determine the value of the height at that probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c9f8d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "618349.6106759505"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pareto_dist.ppf((1-1/7000000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214dfb93",
   "metadata": {},
   "source": [
    "In \"Pareto World\", as the book calls it, we would expet the tallest person to be 618km tall.\n",
    "\n",
    "\n",
    "# Exercise 6-1\n",
    "\n",
    "We will begin by importing the packages and data needed for the exercise, using the recommended code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d191358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data (from previous assignments)\n",
    "from os.path import basename, exists\n",
    "\n",
    "def download(url):\n",
    "    filename = basename(url)\n",
    "    if not exists(filename):\n",
    "        from urllib.request import urlretrieve\n",
    "\n",
    "        local, _ = urlretrieve(url, filename)\n",
    "        print(\"Downloaded \" + local)\n",
    "\n",
    "\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/hinc.py\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/hinc2.py\")\n",
    "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/hinc06.csv\")\n",
    "\n",
    "import hinc\n",
    "import thinkstats2\n",
    "import hinc2\n",
    "import numpy as np\n",
    "import thinkplot\n",
    "\n",
    "\n",
    "income_df = hinc.ReadData()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc0ae5f",
   "metadata": {},
   "source": [
    "This \"income_df\" dataframe is a summary table of the census data, summarizing respondents witnin income ranges.  With data like this, you can't calculate a true mean of the sample, because we don't know where within the ranges each record sits.  So we use the provided function InterpolateSample() to create a sample that fits the summarized data.  The instructions have us set the upper bound for the last bin $1,000,000, or 10^6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba76c275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function provided by text in hinc2.py\n",
    "\n",
    "def InterpolateSample(df, log_upper=6.0):\n",
    "    \"\"\"Makes a sample of log10 household income.\n",
    "\n",
    "    Assumes that log10 income is uniform in each range.\n",
    "\n",
    "    df: DataFrame with columns income and freq\n",
    "    log_upper: log10 of the assumed upper bound for the highest range\n",
    "\n",
    "    returns: NumPy array of log10 household income\n",
    "    \"\"\"\n",
    "    # compute the log10 of the upper bound for each range\n",
    "    df['log_upper'] = np.log10(df.income)\n",
    "\n",
    "    # get the lower bounds by shifting the upper bound and filling in\n",
    "    # the first element\n",
    "    df['log_lower'] = df.log_upper.shift(1)\n",
    "    df.loc[0, 'log_lower'] = 3.0\n",
    "\n",
    "    # plug in a value for the unknown upper bound of the highest range\n",
    "    df.loc[41, 'log_upper'] = log_upper\n",
    "    \n",
    "    # use the freq column to generate the right number of values in\n",
    "    # each range\n",
    "    arrays = []\n",
    "    for _, row in df.iterrows():\n",
    "        vals = np.linspace(row.log_lower, row.log_upper, int(row.freq))\n",
    "        arrays.append(vals)\n",
    "\n",
    "    # collect the arrays into a single sample\n",
    "    log_sample = np.concatenate(arrays)\n",
    "    return log_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82b79770",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sample = InterpolateSample(income_df, log_upper=6.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d458fa0e",
   "metadata": {},
   "source": [
    "The array needs to be converted back out of log10.  The text shows us how to do this with numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84511007",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.power(10, log_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dfef84",
   "metadata": {},
   "source": [
    "We can now calculate the median, mean, skewness and Pearson's skewness, using the functions for moments provided in the text, (pgs 72-74)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94ea5a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RawMoment(xs, k):\n",
    "    return sum(x**k for x in xs) / len(xs)\n",
    "\n",
    "def Mean(xs):\n",
    "    return RawMoment(xs, 1)\n",
    "\n",
    "def CentralMoment(xs, k):\n",
    "    mean = RawMoment(xs, 1)\n",
    "    return sum((x - mean)**k for x in xs) / len(xs)\n",
    "\n",
    "def Var(xs):\n",
    "    return CentralMoment(xs, 2)\n",
    "\n",
    "def StandardizedMoment(xs, k):\n",
    "    var = CentralMoment(xs, 2)\n",
    "    std = np.sqrt(var)\n",
    "    return CentralMoment(xs, k) / std**k\n",
    "\n",
    "def Skewness(xs):\n",
    "    return StandardizedMoment(xs, 3)\n",
    "\n",
    "def Median(xs):\n",
    "    cdf = thinkstats2.Cdf(xs)\n",
    "    return cdf.Value(0.5)\n",
    "\n",
    "def PearsonMedianSkewness(xs):\n",
    "    median = Median(xs)\n",
    "    mean = RawMoment(xs, 1)\n",
    "    var = CentralMoment(xs, 2)\n",
    "    std = np.sqrt(var)\n",
    "    gp = 3 * (mean - median) / std\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1bb8c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  74278.70753118733\n",
      "Median:  51226.45447894046\n",
      "Skewness:  4.949920244429583\n",
      "Pearson Median Skewness:  0.7361258019141782\n"
     ]
    }
   ],
   "source": [
    "mean = Mean(sample)\n",
    "median = Median(sample)\n",
    "skewness = Skewness(sample)\n",
    "Pearsons = PearsonMedianSkewness(sample)\n",
    "\n",
    "print('Mean: ',  mean)\n",
    "print('Median: ',  median)\n",
    "print('Skewness: ',  skewness)\n",
    "print('Pearson Median Skewness: ',  Pearsons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a014260",
   "metadata": {},
   "source": [
    "Now, we'll use thinkstats2 to calculate the probability of falling below the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "053815f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.660005879566872"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf = thinkstats2.Cdf(sample)\n",
    "\n",
    "cdf.Prob(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a415fc6",
   "metadata": {},
   "source": [
    "This result is influenced by the choice we made in creating the interpolated sample.  Because we limited the upper salary to  1 million dollars, the mean is lower than it would be if there were say some billionaire outliers pulling up the mean.  To demonstrate this, I'll run a quick version where the upper limit for income is set to $10 billion instead of $1 million."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0bb0de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New mean:  22526983.866709236 Probability beneath the mean:  0.986330007022816\n"
     ]
    }
   ],
   "source": [
    "log_sample2 = InterpolateSample(income_df, log_upper=10.0)\n",
    "sample2 = np.power(10, log_sample2)\n",
    "mean2 = Mean(sample2)\n",
    "cdf2 = thinkstats2.Cdf(sample2)\n",
    "\n",
    "print('New mean: ' , mean2, 'Probability beneath the mean: ' , cdf2.Prob(mean2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a772988f",
   "metadata": {},
   "source": [
    "Allowing for some very high incomes in the data pulls the mean up to the point that most of the interpolated sample falls below the mean."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
